# ğŸŸ¢ 5. Lancer le Pipeline de Streaming Temps RÃ©el

Une fois lâ€™architecture mise en place (Kafka, Spark, PostgreSQL), cette Ã©tape permet de dÃ©marrer tout le pipeline (producteurs + consommateurs) et de vÃ©rifier que les donnÃ©es circulent bien.

---


## âš ï¸ Ã‰tape indispensable avant de lancer le pipeline

Avant de lancer les producteurs et consommateurs, tu dois **initialiser Spark** depuis le notebook.

Dans le fichier `notebooks/Notebook.ipynb`, exÃ©cute cette cellule pour crÃ©er la `SparkSession` :

```python
from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName("CryptoStockRealTimeProcessing") \
    .master("spark://spark-master:7077") \
    .config("spark.executor.memory", "2g") \
    .config("spark.jars", "/usr/local/spark/jars/postgresql-42.6.0.jar,/usr/local/spark/jars/spark-sql-kafka-0-10_2.12-3.4.0.jar,/usr/local/spark/jars/kafka-clients-2.8.0.jar") \
    .getOrCreate()

print(f"Spark version: {spark.version}")
```
---

## ğŸ“¦ Contenu du pipeline

- **Producer Crypto** : rÃ©cupÃ¨re les prix en temps rÃ©el via l'API CryptoCompare â†’ envoie vers `crypto_topic` Kafka
- **Producer Stocks** : rÃ©cupÃ¨re les actions via lâ€™API Finnhub â†’ envoie vers `stock_topic`
- **Consumer Crypto** : consomme `crypto_topic` et insÃ¨re dans PostgreSQL
- **Consumer Stocks** : consomme `stock_topic` et insÃ¨re dans PostgreSQL

---

## ğŸš€ Lancement automatique (Windows)

ExÃ©cute simplement le script suivant pour tout dÃ©marrer :

```bash
start_pipeline.bat
```

Cela ouvrira **quatre fenÃªtres** :
- `producer_crypto.py`
- `producer_stocks.py`
- `consumer_crypto.py`
- `consumer_stocks.py`

ğŸ›‘ Pour arrÃªter : utilise `Ctrl + C` dans chaque fenÃªtre ou ferme-la manuellement.

---

## ğŸ’» Lancement manuel (depuis un terminal)

Tu peux aussi exÃ©cuter manuellement chaque fichier :

```bash
python producers/producer_crypto.py
python producers/producer_stocks.py

# Attendre 5 secondes
python consumers/consumer_crypto.py
python consumers/consumer_stocks.py
```

---

## ğŸ§ª VÃ©rification

- ğŸ“¬ **Kafka** : Tu verras dans le terminal des messages `envoyÃ©s` et `reÃ§us`
- ğŸ“Š **PostgreSQL** : Connecte-toi Ã  la base :
```bash
docker exec -it pg-ds-dellstore psql -U postgres -d crypto_finance_db
```

Puis exÃ©cute :
```sql
SELECT * FROM crypto_data;
SELECT * FROM stock_data;
```

---

## âš ï¸ PrÃ©-requis

- Le fichier `.env` doit exister Ã  la racine avec tes identifiants